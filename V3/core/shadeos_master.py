#!/usr/bin/env python3
"""
ğŸ–¤ SHADEOS MASTER V3 - EntitÃ© Principale avec Prompts Externes
ImplÃ©mentation basÃ©e sur insight_shadeos.md avec prompts externalisÃ©s
"""

import os
import json
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

from prompt_manager import get_prompt_manager

# Import du module Alma local
from alma_env_loader import get_alma_env_loader


class ShadEOSMaster:
    """ğŸ–¤ EntitÃ© principale ShadEOS V3 - MaÃ®tre stratÃ©gique avec prompts externes"""
    
    def __init__(self, base_dir: str = "/home/luciedefraiteur/ShadEOS_v1_archive/V3"):
        self.base_dir = Path(base_dir)
        self.logger = self._setup_logging()
        
        # Gestionnaire de prompts
        self.prompt_manager = get_prompt_manager()
        
        # MÃ©moire contextuelle - rÃ¨gle sacrÃ©e : nul n'oublie
        self.memory = {
            'interactions_gemini': [],
            'ordres_lucie': [],
            'rapports_chien': [],
            'cycle_count': 0,
            'last_analysis': None
        }
        
        # Ã‰tat interne
        self.running = False
        self.autonomy_level = 0  # 0 = basique, 3 = autonomie complÃ¨te
        
        self.logger.info("ğŸ–¤ ShadEOS Master V3 initialisÃ© avec prompts externes")
    
    def _setup_logging(self) -> logging.Logger:
        """ğŸ“ Configuration du logging"""
        logger = logging.getLogger('shadeos_master_v3')
        logger.setLevel(logging.INFO)
        
        # CrÃ©er le rÃ©pertoire de logs
        log_dir = self.base_dir / "memory" / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # Handler fichier
        handler = logging.FileHandler(log_dir / "shadeos_master_v3.log")
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def analyser_situation_actuelle(self) -> Dict[str, Any]:
        """ğŸ” Analyse froide de la situation actuelle"""
        situation = {
            'timestamp': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'autonomy': self.autonomy_level,
            'directory': str(self.base_dir),
            'memory_size': len(self.memory['interactions_gemini']),
            'last_cycle_success': self._evaluer_dernier_cycle()
        }
        
        self.logger.info(f"ğŸ” Situation analysÃ©e: cycle {situation['cycle']}")
        return situation
    
    def _evaluer_dernier_cycle(self) -> bool:
        """ğŸ“Š Ã‰valuation du succÃ¨s du dernier cycle"""
        if not self.memory['rapports_chien']:
            return True  # Premier cycle
        
        dernier_rapport = self.memory['rapports_chien'][-1]
        return dernier_rapport.get('success', False)
    
    def generer_requete_gemini(self, situation: Dict[str, Any], contexte_additionnel: str = "") -> str:
        """ğŸŒŸ GÃ©nÃ©ration de requÃªte stratÃ©gique pour Gemini depuis prompt externe"""
        
        # Variables pour le prompt
        variables = {
            'cycle': situation['cycle'],
            'autonomy': situation['autonomy'],
            'directory': situation['directory'],
            'memory_size': situation['memory_size'],
            'last_cycle_success': situation['last_cycle_success'],
            'context': contexte_additionnel or "Cycle de routine"
        }
        
        # Charger et formater le prompt
        requete = self.prompt_manager.formater_prompt("shadeos", "analyse_situation", **variables)
        
        if not requete:
            # Fallback minimal si prompt non trouvÃ©
            requete = f"Gemini, analyse le systÃ¨me ShadEOS cycle {situation['cycle']}"
            self.logger.warning("âš ï¸ Utilisation du openai_real pour requÃªte Gemini")
        
        # Sauvegarder dans la mÃ©moire
        self.memory['interactions_gemini'].append({
            'timestamp': datetime.now().isoformat(),
            'type': 'requete',
            'content': requete,
            'cycle': self.memory['cycle_count'],
            'prompt_source': 'shadeos/analyse_situation'
        })
        
        self.logger.info("ğŸŒŸ RequÃªte Gemini gÃ©nÃ©rÃ©e depuis prompt externe")
        return requete
    
    def traiter_reponse_gemini(self, reponse: str) -> Dict[str, Any]:
        """ğŸ§  Traitement et analyse de la rÃ©ponse Gemini"""
        
        # Sauvegarder la rÃ©ponse
        self.memory['interactions_gemini'].append({
            'timestamp': datetime.now().isoformat(),
            'type': 'reponse',
            'content': reponse,
            'cycle': self.memory['cycle_count']
        })
        
        # Analyse basique de la rÃ©ponse
        analyse = {
            'timestamp': datetime.now().isoformat(),
            'reponse_brute': reponse,
            'longueur': len(reponse),
            'contient_recommandations': 'recommand' in reponse.lower(),
            'contient_actions': 'action' in reponse.lower(),
            'cycle': self.memory['cycle_count']
        }
        
        self.memory['last_analysis'] = analyse
        self.logger.info("ğŸ§  RÃ©ponse Gemini traitÃ©e")
        
        return analyse
    
    def generer_ordres_lucie(self, analyse_gemini: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ‘‘ GÃ©nÃ©ration d'ordres pour Lucie (gestionnaire intermÃ©diaire)"""
        
        # Ordres basÃ©s sur l'analyse Gemini
        ordres = {
            'timestamp': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'type': 'ordres_execution',
            'objectif': 'VÃ©rifier Ã©tat systÃ¨me et exÃ©cuter maintenance',
            'actions_demandees': [
                'Analyser les logs rÃ©cents',
                'VÃ©rifier l\'espace disque disponible', 
                'ContrÃ´ler les processus actifs',
                'Rapporter les mÃ©triques systÃ¨me'
            ],
            'priorite': 'normale',
            'deadline': 'fin_de_cycle'
        }
        
        # Adaptation selon l'analyse Gemini
        if analyse_gemini.get('contient_recommandations'):
            ordres['priorite'] = 'haute'
            ordres['actions_demandees'].append('ImplÃ©menter recommandations Gemini')
        
        # Sauvegarder dans la mÃ©moire
        self.memory['ordres_lucie'].append(ordres)
        
        self.logger.info(f"ğŸ‘‘ Ordres gÃ©nÃ©rÃ©s pour Lucie: {len(ordres['actions_demandees'])} actions")
        return ordres
    
    def recevoir_rapport_chien(self, rapport: Dict[str, Any]) -> None:
        """ğŸ“Š RÃ©ception et traitement du rapport du chien"""
        
        # Enrichir le rapport avec mÃ©tadonnÃ©es
        rapport_enrichi = {
            **rapport,
            'timestamp_reception': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'validated_by': 'shadeos_master_v3'
        }
        
        # Sauvegarder dans la mÃ©moire
        self.memory['rapports_chien'].append(rapport_enrichi)
        
        # Ã‰valuation du rapport
        success = rapport.get('success', False)
        if success:
            self.logger.info("ğŸ“Š Rapport chien reÃ§u: SUCCÃˆS")
        else:
            self.logger.warning("ğŸ“Š Rapport chien reÃ§u: Ã‰CHEC")
    
    def executer_cycle_complet(self) -> Dict[str, Any]:
        """ğŸ”„ ExÃ©cution d'un cycle complet selon insight_shadeos.md"""
        
        self.memory['cycle_count'] += 1
        cycle_start = datetime.now()
        
        self.logger.info(f"ğŸ”„ DÃ‰BUT CYCLE {self.memory['cycle_count']}")
        
        try:
            # 1. Analyse de la situation
            situation = self.analyser_situation_actuelle()
            
            # 2. RequÃªte Ã  Gemini (depuis prompt externe)
            requete_gemini = self.generer_requete_gemini(situation)
            
            # 3. Simulation rÃ©ponse Gemini (pour l'instant)
            reponse_gemini = self._appel_openai_reel_pour_gemini(requete_gemini)
            
            # 4. Traitement de la rÃ©ponse
            analyse = self.traiter_reponse_gemini(reponse_gemini)
            
            # 5. GÃ©nÃ©ration d'ordres pour Lucie
            ordres = self.generer_ordres_lucie(analyse)
            
            # 6. Simulation exÃ©cution par Lucie/Chien
            rapport = self._simuler_execution_lucie_chien(ordres)
            
            # 7. RÃ©ception du rapport
            self.recevoir_rapport_chien(rapport)
            
            # RÃ©sultat du cycle
            cycle_result = {
                'cycle': self.memory['cycle_count'],
                'duration': (datetime.now() - cycle_start).total_seconds(),
                'success': rapport.get('success', False),
                'situation': situation,
                'ordres_generes': len(ordres['actions_demandees']),
                'memory_updated': True,
                'prompt_manager_status': self.prompt_manager.get_status()
            }
            
            self.logger.info(f"ğŸ”„ FIN CYCLE {self.memory['cycle_count']} - SuccÃ¨s: {cycle_result['success']}")
            return cycle_result
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur cycle {self.memory['cycle_count']}: {e}")
            return {
                'cycle': self.memory['cycle_count'],
                'success': False,
                'error': str(e)
            }
    
    def _appel_openai_reel_pour_gemini(self, requete: str) -> str:
        """ğŸŒŸ Simulation temporaire de rÃ©ponse Gemini"""
        return f"""ANALYSE SYSTÃˆME - CYCLE {self.memory['cycle_count']}

Ã‰TAT GLOBAL: SystÃ¨me opÃ©rationnel avec prompts externes
POINTS D'AMÃ‰LIORATION: 
- Optimiser la gestion des prompts
- AmÃ©liorer les logs de debug

ACTIONS RECOMMANDÃ‰ES:
1. VÃ©rifier l'espace disque
2. Analyser les performances
3. Nettoyer les fichiers temporaires

MÃ‰TRIQUES: Performance stable, prompts externalisÃ©s fonctionnels."""
    
    def _simuler_execution_lucie_chien(self, ordres: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ• Simulation temporaire d'exÃ©cution par Lucie/Chien"""
        return {
            'timestamp': datetime.now().isoformat(),
            'ordres_recus': ordres,
            'actions_executees': len(ordres['actions_demandees']),
            'success': True,
            'resultats': [
                'Logs analysÃ©s: 15 fichiers',
                'Espace disque: 85% libre',
                'Processus: 12 actifs',
                'MÃ©triques collectÃ©es'
            ]
        }
    
    def get_status(self) -> Dict[str, Any]:
        """ğŸ“Š Ã‰tat actuel de ShadEOS V3"""
        return {
            'version': 'V3_prompts_externes',
            'running': self.running,
            'cycle_count': self.memory['cycle_count'],
            'autonomy_level': self.autonomy_level,
            'memory_size': {
                'gemini_interactions': len(self.memory['interactions_gemini']),
                'ordres_lucie': len(self.memory['ordres_lucie']),
                'rapports_chien': len(self.memory['rapports_chien'])
            },
            'last_cycle_success': self._evaluer_dernier_cycle(),
            'prompt_manager': self.prompt_manager.get_status()
        }

if __name__ == "__main__":
    # Test basique
    shadeos = ShadEOSMaster()
    print("ğŸ–¤ ShadEOS Master V3 - Test avec prompts externes")
    
    # ExÃ©cuter quelques cycles de test
    for i in range(3):
        result = shadeos.executer_cycle_complet()
        print(f"Cycle {result['cycle']}: {'âœ…' if result['success'] else 'âŒ'}")
        time.sleep(1)
    
    # Afficher le statut final
    status = shadeos.get_status()
    print(f"ğŸ“Š Statut final: {status}")
