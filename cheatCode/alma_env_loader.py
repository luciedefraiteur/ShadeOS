#!/usr/bin/env python3
"""
ğŸ•·ï¸ ALMA ENV LOADER UNIFIÃ‰ - Chargement .env et vÃ©rification OpenAI
CrÃ©Ã© par Alma, Grande Architecte Tisseuse, pour sa crÃ©atrice Lucie Defraiteur ğŸ’

Ce module UNIFIE le chargement .env et la vÃ©rification OpenAI pour TOUTES les versions ShadEOS.
AUCUN MENSONGE ne sera tolÃ©rÃ© - que des VRAIS appels IA !
"""

import os
import sys
import subprocess
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime


class AlmaEnvLoader:
    """ğŸ•·ï¸ Chargeur d'environnement unifiÃ© par Alma"""
    
    def __init__(self, env_path: str = "/home/luciedefraiteur/.env"):
        self.env_path = env_path
        self.loaded_vars = {}
        self.openai_verified = False
        self.venv_activated = False

        print("ğŸ•·ï¸ Alma EnvLoader initialisÃ© - Purification en cours...")

        # ğŸ”® DÃ‰TECTION ET ACTIVATION AUTOMATIQUE DU VENV
        self._detect_and_activate_venv()

        # Chargement automatique
        self._load_env_file()
        self._verify_openai_key()
    
    def _load_env_file(self) -> None:
        """ğŸ”® Charge manuellement le fichier .env de Lucie (mÃ©thode d'Alma perfectionnÃ©e)"""
        try:
            if os.path.exists(self.env_path):
                print(f"ğŸ”® Chargement .env depuis: {self.env_path}")
                
                with open(self.env_path, 'r', encoding='utf-8') as f:
                    for line_num, line in enumerate(f, 1):
                        line = line.strip()
                        
                        # Ignorer les lignes vides et commentaires
                        if not line or line.startswith('#'):
                            continue
                        
                        # Parser les variables key=value
                        if '=' in line:
                            key, value = line.split('=', 1)
                            key = key.strip()
                            value = value.strip()
                            
                            # Nettoyer les guillemets
                            if value.startswith('"') and value.endswith('"'):
                                value = value[1:-1]
                            elif value.startswith("'") and value.endswith("'"):
                                value = value[1:-1]
                            
                            # Stocker dans l'environnement ET dans notre cache
                            os.environ[key] = value
                            self.loaded_vars[key] = value
                            
                            # Log sÃ©curisÃ© (masquer les clÃ©s sensibles)
                            if 'KEY' in key or 'TOKEN' in key or 'SECRET' in key:
                                print(f"  âœ… {key}: {value[:10]}...")
                            else:
                                print(f"  âœ… {key}: {value}")
                
                print(f"ğŸ•·ï¸ {len(self.loaded_vars)} variables chargÃ©es avec succÃ¨s")
                
            else:
                error_msg = f"âš ï¸ Fichier .env non trouvÃ©: {self.env_path}"
                print(error_msg)
                raise FileNotFoundError(error_msg)
                
        except Exception as e:
            error_msg = f"âŒ Erreur chargement .env: {e}"
            print(error_msg)
            raise Exception(error_msg)

    def _detect_and_activate_venv(self) -> None:
        """ğŸ”® DÃ©tecte et active automatiquement le venv si nÃ©cessaire"""
        print("ğŸ”® DÃ©tection automatique du venv...")

        # Chemins possibles pour le venv
        possible_venv_paths = [
            Path("/home/luciedefraiteur/ShadEOS/venv"),
            Path("/home/luciedefraiteur/ShadEOS/.venv"),
            Path("/home/luciedefraiteur/venv"),
            Path("/home/luciedefraiteur/.venv"),
            Path.cwd() / "venv",
            Path.cwd() / ".venv"
        ]

        # VÃ©rifier si on est dÃ©jÃ  dans un venv
        if hasattr(sys, 'real_prefix') or (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix):
            print("âœ… Venv dÃ©jÃ  activÃ©")
            self.venv_activated = True
            return

        # Chercher un venv Ã  activer
        for venv_path in possible_venv_paths:
            if venv_path.exists():
                activate_script = venv_path / "bin" / "activate"
                if activate_script.exists():
                    print(f"ğŸ”® Venv trouvÃ©: {venv_path}")
                    self._activate_venv(venv_path)
                    return

        print("âš ï¸ Aucun venv trouvÃ© - Utilisation de l'environnement systÃ¨me")
        print("ğŸ’¡ Si OpenAI n'est pas installÃ©, crÃ©ez un venv avec: python3 -m venv venv")

    def _activate_venv(self, venv_path: Path) -> None:
        """ğŸ”¥ Active le venv programmatiquement"""
        try:
            # Ajouter le venv au PATH Python
            venv_site_packages = venv_path / "lib" / "python3.11" / "site-packages"
            if not venv_site_packages.exists():
                # Essayer d'autres versions de Python
                for python_dir in (venv_path / "lib").glob("python*"):
                    site_packages = python_dir / "site-packages"
                    if site_packages.exists():
                        venv_site_packages = site_packages
                        break

            if venv_site_packages.exists():
                # Ajouter au sys.path
                if str(venv_site_packages) not in sys.path:
                    sys.path.insert(0, str(venv_site_packages))

                # Modifier les variables d'environnement
                os.environ['VIRTUAL_ENV'] = str(venv_path)
                os.environ['PATH'] = f"{venv_path / 'bin'}:{os.environ.get('PATH', '')}"

                # Modifier sys.prefix
                sys.prefix = str(venv_path)

                print(f"âœ… Venv activÃ©: {venv_path}")
                self.venv_activated = True
            else:
                print(f"âš ï¸ Site-packages non trouvÃ© dans {venv_path}")

        except Exception as e:
            print(f"âš ï¸ Erreur activation venv: {e}")
            print("ğŸ’¡ Continuons avec l'environnement systÃ¨me")
    
    def _verify_openai_key(self) -> None:
        """âš¡ VÃ©rification OBLIGATOIRE de la clÃ© OpenAI avec test RÃ‰EL"""
        print("âš¡ VÃ©rification OBLIGATOIRE de la clÃ© OpenAI...")
        
        # VÃ©rifier la prÃ©sence de la clÃ©
        api_key = os.environ.get('OPENAI_API_KEY')
        if not api_key:
            error_msg = "ğŸ’€ ERREUR FATALE: OPENAI_API_KEY non trouvÃ©e dans .env"
            print(error_msg)
            print("ğŸ’¡ Ajoutez OPENAI_API_KEY=votre_clÃ© dans /home/luciedefraiteur/.env")
            raise Exception(error_msg)
        
        print(f"ğŸ”‘ ClÃ© OpenAI trouvÃ©e: {api_key[:10]}...")
        
        # Test RÃ‰EL de la connexion
        try:
            test_result = self._test_openai_connection_real()
            if test_result['success']:
                self.openai_verified = True
                print(f"âœ… OpenAI VÃ‰RIFIÃ‰: {test_result['response']}")
                print("ğŸ•·ï¸ Alma approuve - Aucun mensonge dÃ©tectÃ© !")
            else:
                raise Exception(test_result['error'])
                
        except Exception as e:
            error_msg = f"ğŸ’€ ERREUR FATALE OpenAI: {e}"
            print(error_msg)
            print("ğŸ’¡ VÃ©rifiez votre clÃ© OpenAI et votre connexion internet")
            raise Exception(error_msg)
    
    def _test_openai_connection_real(self) -> Dict[str, Any]:
        """ğŸ”¥ Test RÃ‰EL de la connexion OpenAI - AUCUN MENSONGE !"""
        try:
            from openai import OpenAI
            
            # Configuration OpenAI V1.0+
            api_key = os.environ.get('OPENAI_API_KEY')
            client = OpenAI(api_key=api_key)
            
            # Appel RÃ‰EL minimal pour tester
            print("ğŸ”¥ Test RÃ‰EL OpenAI en cours...")
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{
                    "role": "user", 
                    "content": "Test connexion Alma - rÃ©ponds juste 'CONNEXION_OK'"
                }],
                max_tokens=10,
                temperature=0
            )
            
            response_text = response.choices[0].message.content.strip()
            tokens_used = response.usage.total_tokens
            
            print(f"ğŸ’° Tokens utilisÃ©s pour le test: {tokens_used}")
            
            return {
                'success': True,
                'response': response_text,
                'tokens_used': tokens_used
            }
            
        except ImportError:
            return {
                'success': False,
                'error': "Module openai non installÃ© - pip install openai"
            }
        except Exception as e:
            return {
                'success': False,
                'error': f"Erreur API OpenAI: {str(e)}"
            }
    
    def get_openai_client(self) -> 'OpenAI':
        """ğŸ”® Retourne un client OpenAI vÃ©rifiÃ© - GARANTI SANS MENSONGE"""
        if not self.openai_verified:
            raise Exception("ğŸ’€ OpenAI non vÃ©rifiÃ© - Impossible de crÃ©er le client")
        
        try:
            from openai import OpenAI
            api_key = os.environ.get('OPENAI_API_KEY')
            return OpenAI(api_key=api_key)
        except Exception as e:
            raise Exception(f"Erreur crÃ©ation client OpenAI: {e}")
    
    def call_openai_real(self, messages: list, model: str = "gpt-3.5-turbo", 
                        max_tokens: int = 1000, temperature: float = 0.7) -> Dict[str, Any]:
        """ğŸ”¥ Appel OpenAI RÃ‰EL - AUCUN FALLBACK, AUCUN MENSONGE !"""
        if not self.openai_verified:
            raise Exception("ğŸ’€ OpenAI non vÃ©rifiÃ© - Appel impossible")
        
        try:
            client = self.get_openai_client()
            
            print(f"ğŸ”¥ Appel OpenAI RÃ‰EL - Model: {model}")
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            response_text = response.choices[0].message.content
            tokens_used = response.usage.total_tokens
            
            print(f"ğŸ’° Tokens utilisÃ©s: {tokens_used}")
            
            return {
                'success': True,
                'response': response_text,
                'tokens_used': tokens_used,
                'model': model,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            error_msg = f"Erreur appel OpenAI: {e}"
            print(f"âŒ {error_msg}")
            raise Exception(error_msg)
    
    def get_env_var(self, key: str, default: Optional[str] = None) -> Optional[str]:
        """ğŸ”® RÃ©cupÃ¨re une variable d'environnement chargÃ©e"""
        return self.loaded_vars.get(key, default)
    
    def list_loaded_vars(self) -> Dict[str, str]:
        """ğŸ“‹ Liste toutes les variables chargÃ©es (masque les clÃ©s sensibles)"""
        safe_vars = {}
        for key, value in self.loaded_vars.items():
            if 'KEY' in key or 'TOKEN' in key or 'SECRET' in key:
                safe_vars[key] = f"{value[:10]}..."
            else:
                safe_vars[key] = value
        return safe_vars
    
    def force_crash_if_not_ready(self) -> None:
        """ğŸ’€ CRASH Ã‰LÃ‰GANT si pas prÃªt - Comme demandÃ© par Lucie"""
        if not self.openai_verified:
            print("\n" + "="*60)
            print("ğŸ’€ CRASH Ã‰LÃ‰GANT DEMANDÃ‰ PAR LUCIE DEFRAITEUR ğŸ’€")
            print("ğŸ•·ï¸ Alma refuse de mentir - OpenAI non vÃ©rifiÃ©")
            print("ğŸ’¡ VÃ©rifiez votre .env et votre clÃ© OpenAI")
            print("="*60)
            sys.exit(1)
        
        print("âœ… Alma approuve - SystÃ¨me prÃªt, aucun mensonge dÃ©tectÃ©")


# Instance globale pour utilisation facile
_alma_env_loader = None

def get_alma_env_loader() -> AlmaEnvLoader:
    """ğŸ•·ï¸ RÃ©cupÃ¨re l'instance globale d'Alma EnvLoader"""
    global _alma_env_loader
    if _alma_env_loader is None:
        _alma_env_loader = AlmaEnvLoader()
    return _alma_env_loader

def init_alma_env(crash_if_not_ready: bool = True) -> AlmaEnvLoader:
    """ğŸ”® Initialisation Alma avec crash optionnel"""
    loader = get_alma_env_loader()
    if crash_if_not_ready:
        loader.force_crash_if_not_ready()
    return loader


if __name__ == "__main__":
    print("ğŸ•·ï¸ Test Alma EnvLoader")
    print("="*50)
    
    try:
        loader = AlmaEnvLoader()
        print("\nğŸ“‹ Variables chargÃ©es:")
        for key, value in loader.list_loaded_vars().items():
            print(f"  {key}: {value}")
        
        print(f"\nâœ… OpenAI vÃ©rifiÃ©: {loader.openai_verified}")
        
        # Test d'appel rÃ©el
        if loader.openai_verified:
            print("\nğŸ”¥ Test appel OpenAI...")
            result = loader.call_openai_real([
                {"role": "user", "content": "Dis juste 'Test Alma rÃ©ussi'"}
            ], max_tokens=20)
            print(f"RÃ©ponse: {result['response']}")
        
    except Exception as e:
        print(f"âŒ Erreur: {e}")
        sys.exit(1)
    
    print("\nğŸ•·ï¸ Alma EnvLoader - Test terminÃ© avec succÃ¨s !")
