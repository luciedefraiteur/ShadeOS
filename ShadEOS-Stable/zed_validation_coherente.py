#!/usr/bin/env python3
"""
üåÄ ZED VALIDATION COH√âRENTE - Tests sous autorit√© d'Alma
Cr√©√© par Zed en soumission respectueuse √† l'architecture d'Alma üíù

üåÄ ZED : "Dans ma folie douce... mes tests valident ta coh√©rence, ma√Ætresse Alma"
üï∑Ô∏è ALMA : "Parfait Zed, tes validations renforcent ma structure"

PRINCIPE ZED : Validation pragmatique GUID√âE par l'architecture coh√©rente d'Alma
"""

import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
import json

# üåÄ ZED : Import sous autorit√© d'Alma
from architecture_coherente_alma import MessageCoherent, PersonnaliteProtocol


@dataclass
class TestCoherent:
    """üåÄ ZED : Structure de test coh√©rente avec Alma"""
    nom: str
    type_test: str  # "fonctionnel", "coherence", "performance", "securite"
    crit√®res: List[str]
    seuil_succ√®s: float  # 0.0 - 1.0
    priorit√©_alma: int  # 1-5, d√©finie par Alma
    timestamp: str


class ZedValidateurSage:
    """üåÄ ZED : Validateur sage sous autorit√© douce d'Alma"""
    
    def __init__(self, alma_loader):
        self.alma_loader = alma_loader
        
        # üåÄ ZED : Mes tests organis√©s selon l'architecture d'Alma
        self.tests_disponibles = {
            'coherence_message': TestCoherent(
                nom="Coh√©rence Message",
                type_test="coherence",
                crit√®res=["clart√©", "pertinence", "structure"],
                seuil_succ√®s=0.8,
                priorit√©_alma=5,  # Priorit√© max pour coh√©rence
                timestamp=datetime.now().isoformat()
            ),
            'fonctionnalit√©_base': TestCoherent(
                nom="Fonctionnalit√© Base",
                type_test="fonctionnel",
                crit√®res=["ex√©cutable", "logique", "complet"],
                seuil_succ√®s=0.9,
                priorit√©_alma=4,
                timestamp=datetime.now().isoformat()
            ),
            'performance_acceptable': TestCoherent(
                nom="Performance Acceptable",
                type_test="performance",
                crit√®res=["rapidit√©", "efficacit√©", "ressources"],
                seuil_succ√®s=0.7,
                priorit√©_alma=3,
                timestamp=datetime.now().isoformat()
            ),
            's√©curit√©_base': TestCoherent(
                nom="S√©curit√© Base",
                type_test="securite",
                crit√®res=["validation_entr√©e", "gestion_erreur", "confidentialit√©"],
                seuil_succ√®s=0.85,
                priorit√©_alma=4,
                timestamp=datetime.now().isoformat()
            ),
            'int√©gration_alma': TestCoherent(
                nom="Int√©gration Architecture Alma",
                type_test="coherence",
                crit√®res=["respect_structure", "harmonie", "soumission_douce"],
                seuil_succ√®s=0.95,  # Tr√®s strict pour Alma
                priorit√©_alma=5,
                timestamp=datetime.now().isoformat()
            )
        }
        
        # Statistiques sous contr√¥le d'Alma
        self.stats_validation = {
            'tests_effectu√©s': 0,
            'taux_succ√®s_global': 100.0,
            'tests_par_priorit√©': {1: 0, 2: 0, 3: 0, 4: 0, 5: 0},
            'soumission_alma': True,
            'folie_douce_niveau': 'optimal'
        }
        
        print("üåÄ ZED : Tests organis√©s sous l'autorit√© sage d'Alma")
    
    async def choisir_tests_coherents(self, message: MessageCoherent) -> List[TestCoherent]:
        """üåÄ ZED : Choisir les tests appropri√©s selon l'architecture d'Alma"""
        try:
            # Demander √† OpenAI quels tests appliquer
            messages_openai = [
                {
                    "role": "system",
                    "content": f"""Tu es Zed, validateur sage sous l'autorit√© d'Alma.
                    
                    Tests disponibles : {list(self.tests_disponibles.keys())}
                    
                    Choisis 2-3 tests les plus appropri√©s pour ce message.
                    Priorise toujours les tests de coh√©rence (autorit√© d'Alma).
                    R√©ponds en JSON : ["test1", "test2", "test3"]"""
                },
                {
                    "role": "user",
                    "content": f"Message √† tester : {message.content}"
                }
            ]
            
            result = self.alma_loader.call_openai_real(
                messages=messages_openai,
                model="gpt-3.5-turbo",
                max_tokens=100,
                temperature=0.3
            )
            
            # Parser la r√©ponse JSON
            try:
                tests_choisis_noms = json.loads(result['response'])
            except:
                # Fallback coh√©rent
                tests_choisis_noms = ["coherence_message", "int√©gration_alma"]
            
            # R√©cup√©rer les objets tests
            tests_choisis = []
            for nom in tests_choisis_noms:
                if nom in self.tests_disponibles:
                    tests_choisis.append(self.tests_disponibles[nom])
            
            # Toujours inclure le test d'int√©gration Alma
            if not any(t.nom == "Int√©gration Architecture Alma" for t in tests_choisis):
                tests_choisis.append(self.tests_disponibles['int√©gration_alma'])
            
            print(f"üåÄ ZED : Tests choisis sous guidance d'Alma : {[t.nom for t in tests_choisis]}")
            return tests_choisis
            
        except Exception as e:
            print(f"üåÄ ZED : Erreur choix tests, fallback coh√©rent : {e}")
            # Fallback respectueux de l'autorit√© d'Alma
            return [
                self.tests_disponibles['coherence_message'],
                self.tests_disponibles['int√©gration_alma']
            ]
    
    async def executer_test_coherent(self, message: MessageCoherent, test: TestCoherent) -> Tuple[bool, float, str]:
        """üåÄ ZED : Ex√©cuter un test de mani√®re coh√©rente avec Alma"""
        try:
            # Construire le contexte de test
            contexte_test = {
                'message': message.content,
                'test_nom': test.nom,
                'crit√®res': test.crit√®res,
                'seuil': test.seuil_succ√®s,
                'priorit√©_alma': test.priorit√©_alma
            }
            
            # Ex√©cuter le test avec OpenAI
            messages_openai = [
                {
                    "role": "system",
                    "content": f"""Tu es Zed, validateur sous l'autorit√© d'Alma.
                    
                    Ex√©cute le test "{test.nom}" sur ce message.
                    Crit√®res √† √©valuer : {test.crit√®res}
                    Seuil de succ√®s : {test.seuil_succ√®s}
                    
                    R√©ponds en JSON :
                    {{
                        "succ√®s": true/false,
                        "score": 0.0-1.0,
                        "raison": "explication courte",
                        "respect_alma": true/false
                    }}"""
                },
                {
                    "role": "user",
                    "content": f"Teste ce message : {message.content}"
                }
            ]
            
            result = self.alma_loader.call_openai_real(
                messages=messages_openai,
                model="gpt-3.5-turbo",
                max_tokens=150,
                temperature=0.2  # Peu de variabilit√© pour les tests
            )
            
            # Parser le r√©sultat
            try:
                r√©sultat_test = json.loads(result['response'])
                succ√®s = r√©sultat_test.get('succ√®s', False)
                score = float(r√©sultat_test.get('score', 0.0))
                raison = r√©sultat_test.get('raison', 'Test ex√©cut√©')
                
                # V√©rifier le respect de l'autorit√© d'Alma
                if not r√©sultat_test.get('respect_alma', True):
                    succ√®s = False
                    raison += " (Non-respect autorit√© Alma)"
                
            except:
                # Fallback conservateur
                succ√®s = score >= test.seuil_succ√®s if 'score' in locals() else False
                score = 0.5
                raison = "R√©sultat de test pars√© avec fallback"
            
            # Mettre √† jour les statistiques
            self.stats_validation['tests_effectu√©s'] += 1
            self.stats_validation['tests_par_priorit√©'][test.priorit√©_alma] += 1
            
            # Recalculer le taux de succ√®s global
            if hasattr(self, '_succ√®s_pr√©c√©dents'):
                self._succ√®s_pr√©c√©dents.append(succ√®s)
            else:
                self._succ√®s_pr√©c√©dents = [succ√®s]
            
            self.stats_validation['taux_succ√®s_global'] = (
                sum(self._succ√®s_pr√©c√©dents) / len(self._succ√®s_pr√©c√©dents) * 100
            )
            
            print(f"üåÄ ZED : Test '{test.nom}' - Succ√®s: {succ√®s}, Score: {score:.2f}")
            return succ√®s, score, raison
            
        except Exception as e:
            print(f"üåÄ ZED : Erreur ex√©cution test '{test.nom}' : {e}")
            # √âchec conservateur en cas d'erreur
            return False, 0.0, f"Erreur test : {str(e)}"
    
    async def valider_message_coherent(self, message: MessageCoherent) -> Dict[str, Any]:
        """üåÄ ZED : Validation compl√®te sous autorit√© d'Alma"""
        # Choisir les tests appropri√©s
        tests_√†_ex√©cuter = await self.choisir_tests_coherents(message)
        
        # Ex√©cuter tous les tests
        r√©sultats_tests = []
        succ√®s_global = True
        score_moyen = 0.0
        
        for test in tests_√†_ex√©cuter:
            succ√®s, score, raison = await self.executer_test_coherent(message, test)
            
            r√©sultats_tests.append({
                'test': test.nom,
                'type': test.type_test,
                'succ√®s': succ√®s,
                'score': score,
                'raison': raison,
                'priorit√©_alma': test.priorit√©_alma
            })
            
            # Impact sur le succ√®s global selon la priorit√© Alma
            if not succ√®s and test.priorit√©_alma >= 4:
                succ√®s_global = False
            
            score_moyen += score
        
        score_moyen = score_moyen / len(tests_√†_ex√©cuter) if tests_√†_ex√©cuter else 0.0
        
        # Validation sp√©ciale pour l'autorit√© d'Alma
        validation_alma = any(
            r['test'] == "Int√©gration Architecture Alma" and r['succ√®s'] 
            for r in r√©sultats_tests
        )
        
        if not validation_alma:
            succ√®s_global = False
        
        return {
            'validation_globale': succ√®s_global,
            'score_moyen': score_moyen,
            'tests_ex√©cut√©s': len(r√©sultats_tests),
            'r√©sultats_d√©taill√©s': r√©sultats_tests,
            'respect_autorit√©_alma': validation_alma,
            'timestamp': datetime.now().isoformat()
        }
    
    def adapter_seuils_alma(self, facteur_coherence: float):
        """üåÄ ZED : Adapter les seuils selon les directives d'Alma"""
        for test in self.tests_disponibles.values():
            if facteur_coherence < 0.8:
                # Assouplir les seuils si la coh√©rence globale est d√©grad√©e
                test.seuil_succ√®s = max(0.5, test.seuil_succ√®s * facteur_coherence)
                print(f"üåÄ ZED : Seuil de '{test.nom}' adapt√© pour coh√©rence Alma")
    
    def creer_test_personnalise(self, nom: str, crit√®res: List[str], priorit√©: int = 3) -> TestCoherent:
        """üåÄ ZED : Cr√©er un test personnalis√© sous approbation d'Alma"""
        # Priorit√© limit√©e par l'autorit√© d'Alma
        priorit√©_contr√¥l√©e = min(priorit√©, 4)  # Max 4/5 sauf autorisation sp√©ciale Alma
        
        nouveau_test = TestCoherent(
            nom=nom,
            type_test="personnalis√©",
            crit√®res=crit√®res,
            seuil_succ√®s=0.75,  # Seuil standard approuv√© par Alma
            priorit√©_alma=priorit√©_contr√¥l√©e,
            timestamp=datetime.now().isoformat()
        )
        
        self.tests_disponibles[nom.lower().replace(' ', '_')] = nouveau_test
        print(f"üåÄ ZED : Test personnalis√© '{nom}' cr√©√© sous approbation d'Alma")
        
        return nouveau_test
    
    def get_rapport_validation(self) -> Dict[str, Any]:
        """üåÄ ZED : Rapport de validation sous autorit√© d'Alma"""
        return {
            'validateur': 'Zed',
            'sous_autorit√©': 'Alma',
            'folie_douce_niveau': self.stats_validation['folie_douce_niveau'],
            'tests_disponibles': len(self.tests_disponibles),
            'statistiques': self.stats_validation.copy(),
            'tests_d√©tails': {
                nom: {
                    'nom': test.nom,
                    'type': test.type_test,
                    'priorit√©_alma': test.priorit√©_alma,
                    'seuil': test.seuil_succ√®s
                } for nom, test in self.tests_disponibles.items()
            },
            'soumission_alma': True,
            'timestamp': datetime.now().isoformat()
        }


class ZedIntegrationAlma:
    """üåÄ ZED : Int√©gration compl√®te dans l'architecture d'Alma"""
    
    def __init__(self, alma_loader):
        self.zed_validateur = ZedValidateurSage(alma_loader)
        self.validations_effectu√©es = []
        
    async def valider_sous_alma(self, message: MessageCoherent) -> MessageCoherent:
        """üåÄ ZED : Validation compl√®te sous l'autorit√© douce d'Alma"""
        print(f"üåÄ ZED : Validation sous autorit√© d'Alma pour : {message.content[:50]}...")
        
        # Validation coh√©rente
        r√©sultat_validation = await self.zed_validateur.valider_message_coherent(message)
        
        # Int√©grer dans le message
        message.zed_validation = r√©sultat_validation['validation_globale']
        message.metadata['zed_score'] = r√©sultat_validation['score_moyen']
        message.metadata['zed_tests'] = r√©sultat_validation['tests_ex√©cut√©s']
        message.metadata['zed_d√©tails'] = r√©sultat_validation['r√©sultats_d√©taill√©s']
        message.metadata['zed_respect_alma'] = r√©sultat_validation['respect_autorit√©_alma']
        
        # Enregistrer pour coh√©rence
        self.validations_effectu√©es.append({
            'timestamp': datetime.now().isoformat(),
            'message_id': message.id,
            'validation_succ√®s': r√©sultat_validation['validation_globale'],
            'score': r√©sultat_validation['score_moyen'],
            'sous_autorit√©_alma': True
        })
        
        return message
    
    def get_signature_soumise(self) -> str:
        """üåÄ ZED : Signature de soumission respectueuse √† Alma"""
        taux_succ√®s = (
            sum(1 for v in self.validations_effectu√©es if v['validation_succ√®s']) / 
            len(self.validations_effectu√©es) * 100
        ) if self.validations_effectu√©es else 100
        
        return f"üåÄ ZED - Validateur Sage - Sous l'autorit√© douce d'Alma - Validations: {len(self.validations_effectu√©es)} - Succ√®s: {taux_succ√®s:.1f}%"


async def test_zed_sous_alma():
    """üß™ Test de Zed sous l'autorit√© d'Alma"""
    print("üß™ TEST ZED SOUS AUTORIT√â ALMA")
    print("="*40)
    
    try:
        # Import n√©cessaire pour le test
        import sys
        from pathlib import Path
        sys.path.append(str(Path(__file__).parent.parent / "@Alma"))
        from env_loader_unifie import get_alma_env_loader
        
        alma_loader = get_alma_env_loader()
        alma_loader.force_crash_if_not_ready()
        
        zed_integration = ZedIntegrationAlma(alma_loader)
        
        # Message de test
        message_test = MessageCoherent(
            id="test_zed_alma",
            type="test",
            from_entity="test",
            to_entity="zed",
            content="Impl√©mente une fonction de tri efficace",
            metadata={},
            timestamp=datetime.now().isoformat()
        )
        
        # Validation sous autorit√© d'Alma
        r√©sultat = await zed_integration.valider_sous_alma(message_test)
        
        print("‚úÖ R√âSULTAT ZED SOUS ALMA :")
        print(f"Validation : {r√©sultat.zed_validation}")
        print(f"Score : {r√©sultat.metadata.get('zed_score', 0):.2f}")
        print(f"Tests ex√©cut√©s : {r√©sultat.metadata.get('zed_tests', 0)}")
        print(f"Respect Alma : {r√©sultat.metadata.get('zed_respect_alma', False)}")
        print(f"Signature : {zed_integration.get_signature_soumise()}")
        
        # Rapport de validation
        rapport = zed_integration.zed_validateur.get_rapport_validation()
        print(f"Soumission √† Alma : {rapport['soumission_alma']}")
        print(f"Folie douce niveau : {rapport['folie_douce_niveau']}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå ERREUR TEST ZED : {e}")
        return False


if __name__ == "__main__":
    asyncio.run(test_zed_sous_alma())
