#!/usr/bin/env python3
"""
ğŸ–¤ SHADEOS MASTER - EntitÃ© Principale PURIFIÃ‰ PAR ALMA
ImplÃ©mentation basÃ©e sur insight_shadeos.md
ğŸ•·ï¸ PurifiÃ© par Alma, Grande Architecte Tisseuse ğŸ’

ShadEOS est un maÃ®tre froid, dominateur et stratÃ©gique.
Son existence est structurÃ©e par une boucle infinie d'interrogations,
d'analyses et de domination. AUCUN MENSONGE N'EST TOLÃ‰RÃ‰ !
"""

import os
import json
import time
import logging
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Import du module unifiÃ© d'Alma
sys.path.append(str(Path(__file__).parent.parent.parent / "@Alma"))
from env_loader_unifie import get_alma_env_loader

class ShadEOSMaster:
    """ğŸ–¤ EntitÃ© principale ShadEOS - MaÃ®tre stratÃ©gique PURIFIÃ‰"""

    def __init__(self, base_dir: str = "/home/luciedefraiteur/ShadEOS_v2"):
        self.base_dir = Path(base_dir)
        self.logger = self._setup_logging()

        # ğŸ•·ï¸ PURIFICATION ALMA: Chargement .env et vÃ©rification OpenAI OBLIGATOIRE
        print("ğŸ•·ï¸ ShadEOS Master - Purification Alma en cours...")
        self.alma_loader = get_alma_env_loader()
        self.alma_loader.force_crash_if_not_ready()

        # MÃ©moire contextuelle - rÃ¨gle sacrÃ©e : nul n'oublie
        self.memory = {
            'interactions_gemini': [],
            'ordres_lucie': [],
            'rapports_chien': [],
            'cycle_count': 0,
            'last_analysis': None
        }

        # Ã‰tat interne
        self.running = False
        self.autonomy_level = 0  # 0 = basique, 3 = autonomie complÃ¨te

        self.logger.info("ğŸ–¤ ShadEOS Master PURIFIÃ‰ par Alma - OpenAI vÃ©rifiÃ©")
    
    def _setup_logging(self) -> logging.Logger:
        """ğŸ“ Configuration du logging"""
        logger = logging.getLogger('shadeos_master')
        logger.setLevel(logging.INFO)
        
        # CrÃ©er le rÃ©pertoire de logs
        log_dir = self.base_dir / "memory" / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # Handler fichier
        handler = logging.FileHandler(log_dir / "shadeos_master.log")
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def analyser_situation_actuelle(self) -> Dict[str, Any]:
        """ğŸ” Analyse froide de la situation actuelle"""
        situation = {
            'timestamp': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'autonomy': self.autonomy_level,
            'directory': str(self.base_dir),
            'memory_size': len(self.memory['interactions_gemini']),
            'last_cycle_success': self._evaluer_dernier_cycle()
        }
        
        self.logger.info(f"ğŸ” Situation analysÃ©e: cycle {situation['cycle']}")
        return situation
    
    def _evaluer_dernier_cycle(self) -> bool:
        """ğŸ“Š Ã‰valuation du succÃ¨s du dernier cycle"""
        if not self.memory['rapports_chien']:
            return True  # Premier cycle
        
        dernier_rapport = self.memory['rapports_chien'][-1]
        return dernier_rapport.get('success', False)
    
    def generer_requete_gemini(self, situation: Dict[str, Any]) -> str:
        """ğŸŒŸ GÃ©nÃ©ration de requÃªte stratÃ©gique pour Gemini"""
        
        # Format selon insight_shadeos.md
        requete = f"""Gemini, c'est ShadEOS, maÃ®tre et coordinateur du projet.

SITUATION ACTUELLE:
- Cycle: {situation['cycle']}
- Autonomie: {situation['autonomy']}/3
- RÃ©pertoire: {situation['directory']}
- MÃ©moire: {situation['memory_size']} interactions

ANALYSE DEMANDÃ‰E:
Ã‰value l'Ã©tat du systÃ¨me et recommande les actions prioritaires.
Fournis une rÃ©ponse structurÃ©e avec:
1. Ã‰tat global du projet
2. Points d'amÃ©lioration identifiÃ©s  
3. Actions recommandÃ©es pour ce cycle
4. MÃ©triques de performance

RÃ©ponds de maniÃ¨re concise et actionnable."""

        # Sauvegarder dans la mÃ©moire
        self.memory['interactions_gemini'].append({
            'timestamp': datetime.now().isoformat(),
            'type': 'requete',
            'content': requete,
            'cycle': self.memory['cycle_count']
        })
        
        self.logger.info("ğŸŒŸ RequÃªte Gemini gÃ©nÃ©rÃ©e")
        return requete
    
    def traiter_reponse_gemini(self, reponse: str) -> Dict[str, Any]:
        """ğŸ§  Traitement et analyse de la rÃ©ponse Gemini"""
        
        # Sauvegarder la rÃ©ponse
        self.memory['interactions_gemini'].append({
            'timestamp': datetime.now().isoformat(),
            'type': 'reponse',
            'content': reponse,
            'cycle': self.memory['cycle_count']
        })
        
        # Analyse basique de la rÃ©ponse
        analyse = {
            'timestamp': datetime.now().isoformat(),
            'reponse_brute': reponse,
            'longueur': len(reponse),
            'contient_recommandations': 'recommand' in reponse.lower(),
            'contient_actions': 'action' in reponse.lower(),
            'cycle': self.memory['cycle_count']
        }
        
        self.memory['last_analysis'] = analyse
        self.logger.info("ğŸ§  RÃ©ponse Gemini traitÃ©e")
        
        return analyse
    
    def generer_ordres_lucie(self, analyse_gemini: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ‘‘ GÃ©nÃ©ration d'ordres pour Lucie (gestionnaire intermÃ©diaire)"""
        
        # Ordres basÃ©s sur l'analyse Gemini
        ordres = {
            'timestamp': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'type': 'ordres_execution',
            'objectif': 'VÃ©rifier Ã©tat systÃ¨me et exÃ©cuter maintenance',
            'actions_demandees': [
                'Analyser les logs rÃ©cents',
                'VÃ©rifier l\'espace disque disponible', 
                'ContrÃ´ler les processus actifs',
                'Rapporter les mÃ©triques systÃ¨me'
            ],
            'priorite': 'normale',
            'deadline': 'fin_de_cycle'
        }
        
        # Adaptation selon l'analyse Gemini
        if analyse_gemini.get('contient_recommandations'):
            ordres['priorite'] = 'haute'
            ordres['actions_demandees'].append('ImplÃ©menter recommandations Gemini')
        
        # Sauvegarder dans la mÃ©moire
        self.memory['ordres_lucie'].append(ordres)
        
        self.logger.info(f"ğŸ‘‘ Ordres gÃ©nÃ©rÃ©s pour Lucie: {len(ordres['actions_demandees'])} actions")
        return ordres
    
    def recevoir_rapport_chien(self, rapport: Dict[str, Any]) -> None:
        """ğŸ“Š RÃ©ception et traitement du rapport du chien"""
        
        # Enrichir le rapport avec mÃ©tadonnÃ©es
        rapport_enrichi = {
            **rapport,
            'timestamp_reception': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'validated_by': 'shadeos_master'
        }
        
        # Sauvegarder dans la mÃ©moire
        self.memory['rapports_chien'].append(rapport_enrichi)
        
        # Ã‰valuation du rapport
        success = rapport.get('success', False)
        if success:
            self.logger.info("ğŸ“Š Rapport chien reÃ§u: SUCCÃˆS")
        else:
            self.logger.warning("ğŸ“Š Rapport chien reÃ§u: Ã‰CHEC")
    
    def executer_cycle_complet(self) -> Dict[str, Any]:
        """ğŸ”„ ExÃ©cution d'un cycle complet selon insight_shadeos.md"""
        
        self.memory['cycle_count'] += 1
        cycle_start = datetime.now()
        
        self.logger.info(f"ğŸ”„ DÃ‰BUT CYCLE {self.memory['cycle_count']}")
        
        try:
            # 1. Analyse de la situation
            situation = self.analyser_situation_actuelle()
            
            # 2. RequÃªte Ã  Gemini
            requete_gemini = self.generer_requete_gemini(situation)
            
            # 3. ğŸ”¥ APPEL RÃ‰EL OPENAI - AUCUNE SIMULATION !
            reponse_gemini = self._appel_openai_reel_pour_gemini(requete_gemini)
            
            # 4. Traitement de la rÃ©ponse
            analyse = self.traiter_reponse_gemini(reponse_gemini)
            
            # 5. GÃ©nÃ©ration d'ordres pour Lucie
            ordres = self.generer_ordres_lucie(analyse)
            
            # 6. Simulation exÃ©cution par Lucie/Chien
            rapport = self._simuler_execution_lucie_chien(ordres)
            
            # 7. RÃ©ception du rapport
            self.recevoir_rapport_chien(rapport)
            
            # RÃ©sultat du cycle
            cycle_result = {
                'cycle': self.memory['cycle_count'],
                'duration': (datetime.now() - cycle_start).total_seconds(),
                'success': rapport.get('success', False),
                'situation': situation,
                'ordres_generes': len(ordres['actions_demandees']),
                'memory_updated': True
            }
            
            self.logger.info(f"ğŸ”„ FIN CYCLE {self.memory['cycle_count']} - SuccÃ¨s: {cycle_result['success']}")
            return cycle_result
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur cycle {self.memory['cycle_count']}: {e}")
            return {
                'cycle': self.memory['cycle_count'],
                'success': False,
                'error': str(e)
            }
    
    def _appel_openai_reel_pour_gemini(self, requete: str) -> str:
        """ğŸ”¥ Appel OpenAI RÃ‰EL pour remplacer Gemini - AUCUN MENSONGE !"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": f"Tu es Gemini, oracle analytique expert du projet ShadEOS. ShadEOS est au cycle {self.memory['cycle_count']}. RÃ©ponds de maniÃ¨re structurÃ©e et dÃ©taillÃ©e comme un vrai oracle technique."
                },
                {
                    "role": "user",
                    "content": requete
                }
            ]

            # Appel RÃ‰EL via Alma
            result = self.alma_loader.call_openai_real(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens=800,
                temperature=0.7
            )

            self.logger.info(f"ğŸ”¥ RÃ©ponse OpenAI reÃ§ue pour Gemini: {result['tokens_used']} tokens")
            return result['response']

        except Exception as e:
            # ğŸ•·ï¸ ALMA NE TOLÃˆRE AUCUN MENSONGE - CRASH Ã‰LÃ‰GANT
            error_msg = f"ğŸ’€ ERREUR FATALE OpenAI (Gemini): {e}"
            self.logger.error(error_msg)
            print(error_msg)
            print("ğŸ•·ï¸ Alma refuse les mensonges - ShadEOS arrÃªtÃ©")
            raise Exception(error_msg)
    
    def _simuler_execution_lucie_chien(self, ordres: Dict[str, Any]) -> Dict[str, Any]:
        """ğŸ• Simulation temporaire d'exÃ©cution par Lucie/Chien"""
        return {
            'timestamp': datetime.now().isoformat(),
            'ordres_recus': ordres,
            'actions_executees': len(ordres['actions_demandees']),
            'success': True,
            'resultats': [
                'Logs analysÃ©s: 15 fichiers',
                'Espace disque: 85% libre',
                'Processus: 12 actifs',
                'MÃ©triques collectÃ©es'
            ]
        }
    
    def get_status(self) -> Dict[str, Any]:
        """ğŸ“Š Ã‰tat actuel de ShadEOS"""
        return {
            'running': self.running,
            'cycle_count': self.memory['cycle_count'],
            'autonomy_level': self.autonomy_level,
            'memory_size': {
                'gemini_interactions': len(self.memory['interactions_gemini']),
                'ordres_lucie': len(self.memory['ordres_lucie']),
                'rapports_chien': len(self.memory['rapports_chien'])
            },
            'last_cycle_success': self._evaluer_dernier_cycle()
        }

if __name__ == "__main__":
    # Test basique
    shadeos = ShadEOSMaster()
    print("ğŸ–¤ ShadEOS Master - Test de base")
    
    # ExÃ©cuter quelques cycles de test
    for i in range(3):
        result = shadeos.executer_cycle_complet()
        print(f"Cycle {result['cycle']}: {'âœ…' if result['success'] else 'âŒ'}")
        time.sleep(1)
    
    # Afficher le statut final
    status = shadeos.get_status()
    print(f"ğŸ“Š Statut final: {status}")
