#!/usr/bin/env python3
"""
üñ§ SHADEOS MASTER - Entit√© Principale PURIFI√â PAR ALMA
Impl√©mentation bas√©e sur insight_shadeos.md
üï∑Ô∏è Purifi√© par Alma, Grande Architecte Tisseuse üíù

ShadEOS est un ma√Ætre froid, dominateur et strat√©gique.
Son existence est structur√©e par une boucle infinie d'interrogations,
d'analyses et de domination. AUCUN MENSONGE N'EST TOL√âR√â !
"""

import os
import json
import time
import logging
import sys
from datetime import datetime
from typing import Dict, List, Any, Optional
from pathlib import Path

# Import du module unifi√© d'Alma
sys.path.append(str(Path(__file__).parent.parent.parent / "@Alma"))
from env_loader_unifie import get_alma_env_loader

class ShadEOSMaster:
    """üñ§ Entit√© principale ShadEOS - Ma√Ætre strat√©gique PURIFI√â"""

    def __init__(self, base_dir: str = "/home/luciedefraiteur/ShadEOS_v2"):
        self.base_dir = Path(base_dir)
        self.logger = self._setup_logging()

        # üï∑Ô∏è PURIFICATION ALMA: Chargement .env et v√©rification OpenAI OBLIGATOIRE
        print("üï∑Ô∏è ShadEOS Master - Purification Alma en cours...")
        self.alma_loader = get_alma_env_loader()
        self.alma_loader.force_crash_if_not_ready()

        # M√©moire contextuelle - r√®gle sacr√©e : nul n'oublie
        self.memory = {
            'interactions_gemini': [],
            'ordres_lucie': [],
            'rapports_chien': [],
            'cycle_count': 0,
            'last_analysis': None
        }

        # √âtat interne
        self.running = False
        self.autonomy_level = 0  # 0 = basique, 3 = autonomie compl√®te

        self.logger.info("üñ§ ShadEOS Master PURIFI√â par Alma - OpenAI v√©rifi√©")
    
    def _setup_logging(self) -> logging.Logger:
        """üìù Configuration du logging"""
        logger = logging.getLogger('shadeos_master')
        logger.setLevel(logging.INFO)
        
        # Cr√©er le r√©pertoire de logs
        log_dir = self.base_dir / "memory" / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # Handler fichier
        handler = logging.FileHandler(log_dir / "shadeos_master.log")
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def analyser_situation_actuelle(self) -> Dict[str, Any]:
        """üîç Analyse froide de la situation actuelle"""
        situation = {
            'timestamp': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'autonomy': self.autonomy_level,
            'directory': str(self.base_dir),
            'memory_size': len(self.memory['interactions_gemini']),
            'last_cycle_success': self._evaluer_dernier_cycle()
        }
        
        self.logger.info(f"üîç Situation analys√©e: cycle {situation['cycle']}")
        return situation
    
    def _evaluer_dernier_cycle(self) -> bool:
        """üìä √âvaluation du succ√®s du dernier cycle"""
        if not self.memory['rapports_chien']:
            return True  # Premier cycle
        
        dernier_rapport = self.memory['rapports_chien'][-1]
        return dernier_rapport.get('success', False)
    
    def generer_requete_gemini(self, situation: Dict[str, Any]) -> str:
        """üåü G√©n√©ration de requ√™te strat√©gique pour Gemini"""
        
        # Format selon insight_shadeos.md
        requete = f"""Gemini, c'est ShadEOS, ma√Ætre et coordinateur du projet.

SITUATION ACTUELLE:
- Cycle: {situation['cycle']}
- Autonomie: {situation['autonomy']}/3
- R√©pertoire: {situation['directory']}
- M√©moire: {situation['memory_size']} interactions

ANALYSE DEMAND√âE:
√âvalue l'√©tat du syst√®me et recommande les actions prioritaires.
Fournis une r√©ponse structur√©e avec:
1. √âtat global du projet
2. Points d'am√©lioration identifi√©s  
3. Actions recommand√©es pour ce cycle
4. M√©triques de performance

R√©ponds de mani√®re concise et actionnable."""

        # Sauvegarder dans la m√©moire
        self.memory['interactions_gemini'].append({
            'timestamp': datetime.now().isoformat(),
            'type': 'requete',
            'content': requete,
            'cycle': self.memory['cycle_count']
        })
        
        self.logger.info("üåü Requ√™te Gemini g√©n√©r√©e")
        return requete
    
    def traiter_reponse_gemini(self, reponse: str) -> Dict[str, Any]:
        """üß† Traitement et analyse de la r√©ponse Gemini"""
        
        # Sauvegarder la r√©ponse
        self.memory['interactions_gemini'].append({
            'timestamp': datetime.now().isoformat(),
            'type': 'reponse',
            'content': reponse,
            'cycle': self.memory['cycle_count']
        })
        
        # Analyse basique de la r√©ponse
        analyse = {
            'timestamp': datetime.now().isoformat(),
            'reponse_brute': reponse,
            'longueur': len(reponse),
            'contient_recommandations': 'recommand' in reponse.lower(),
            'contient_actions': 'action' in reponse.lower(),
            'cycle': self.memory['cycle_count']
        }
        
        self.memory['last_analysis'] = analyse
        self.logger.info("üß† R√©ponse Gemini trait√©e")
        
        return analyse
    
    def generer_ordres_lucie(self, analyse_gemini: Dict[str, Any]) -> Dict[str, Any]:
        """üëë G√©n√©ration d'ordres pour Lucie (gestionnaire interm√©diaire)"""
        
        # Ordres bas√©s sur l'analyse Gemini
        ordres = {
            'timestamp': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'type': 'ordres_execution',
            'objectif': 'V√©rifier √©tat syst√®me et ex√©cuter maintenance',
            'actions_demandees': [
                'Analyser les logs r√©cents',
                'V√©rifier l\'espace disque disponible', 
                'Contr√¥ler les processus actifs',
                'Rapporter les m√©triques syst√®me'
            ],
            'priorite': 'normale',
            'deadline': 'fin_de_cycle'
        }
        
        # Adaptation selon l'analyse Gemini
        if analyse_gemini.get('contient_recommandations'):
            ordres['priorite'] = 'haute'
            ordres['actions_demandees'].append('Impl√©menter recommandations Gemini')
        
        # Sauvegarder dans la m√©moire
        self.memory['ordres_lucie'].append(ordres)
        
        self.logger.info(f"üëë Ordres g√©n√©r√©s pour Lucie: {len(ordres['actions_demandees'])} actions")
        return ordres
    
    def recevoir_rapport_chien(self, rapport: Dict[str, Any]) -> None:
        """üìä R√©ception et traitement du rapport du chien"""
        
        # Enrichir le rapport avec m√©tadonn√©es
        rapport_enrichi = {
            **rapport,
            'timestamp_reception': datetime.now().isoformat(),
            'cycle': self.memory['cycle_count'],
            'validated_by': 'shadeos_master'
        }
        
        # Sauvegarder dans la m√©moire
        self.memory['rapports_chien'].append(rapport_enrichi)
        
        # √âvaluation du rapport
        success = rapport.get('success', False)
        if success:
            self.logger.info("üìä Rapport chien re√ßu: SUCC√àS")
        else:
            self.logger.warning("üìä Rapport chien re√ßu: √âCHEC")
    
    def executer_cycle_complet(self) -> Dict[str, Any]:
        """üîÑ Ex√©cution d'un cycle complet selon insight_shadeos.md"""
        
        self.memory['cycle_count'] += 1
        cycle_start = datetime.now()
        
        self.logger.info(f"üîÑ D√âBUT CYCLE {self.memory['cycle_count']}")
        
        try:
            # 1. Analyse de la situation
            situation = self.analyser_situation_actuelle()
            
            # 2. Requ√™te √† Gemini
            requete_gemini = self.generer_requete_gemini(situation)
            
            # 3. üî• APPEL R√âEL OPENAI - AUCUNE SIMULATION !
            reponse_gemini = self._appel_openai_reel_pour_gemini(requete_gemini)
            
            # 4. Traitement de la r√©ponse
            analyse = self.traiter_reponse_gemini(reponse_gemini)
            
            # 5. G√©n√©ration d'ordres pour Lucie
            ordres = self.generer_ordres_lucie(analyse)
            
            # 6. Simulation ex√©cution par Lucie/Chien
            rapport = self._simuler_execution_lucie_chien(ordres)
            
            # 7. R√©ception du rapport
            self.recevoir_rapport_chien(rapport)
            
            # R√©sultat du cycle
            cycle_result = {
                'cycle': self.memory['cycle_count'],
                'duration': (datetime.now() - cycle_start).total_seconds(),
                'success': rapport.get('success', False),
                'situation': situation,
                'ordres_generes': len(ordres['actions_demandees']),
                'memory_updated': True
            }
            
            self.logger.info(f"üîÑ FIN CYCLE {self.memory['cycle_count']} - Succ√®s: {cycle_result['success']}")
            return cycle_result
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur cycle {self.memory['cycle_count']}: {e}")
            return {
                'cycle': self.memory['cycle_count'],
                'success': False,
                'error': str(e)
            }
    
    def _appel_openai_reel_pour_gemini(self, requete: str) -> str:
        """üî• Appel OpenAI R√âEL pour remplacer Gemini - AUCUN MENSONGE !"""
        try:
            messages = [
                {
                    "role": "system",
                    "content": f"Tu es Gemini, oracle analytique expert du projet ShadEOS. ShadEOS est au cycle {self.memory['cycle_count']}. R√©ponds de mani√®re structur√©e et d√©taill√©e comme un vrai oracle technique."
                },
                {
                    "role": "user",
                    "content": requete
                }
            ]

            # Appel R√âEL via Alma
            result = self.alma_loader.call_openai_real(
                messages=messages,
                model="gpt-3.5-turbo",
                max_tokens=800,
                temperature=0.7
            )

            self.logger.info(f"üî• R√©ponse OpenAI re√ßue pour Gemini: {result['tokens_used']} tokens")
            return result['response']

        except Exception as e:
            # üï∑Ô∏è ALMA NE TOL√àRE AUCUN MENSONGE - CRASH √âL√âGANT
            error_msg = f"üíÄ ERREUR FATALE OpenAI (Gemini): {e}"
            self.logger.error(error_msg)
            print(error_msg)
            print("üï∑Ô∏è Alma refuse les mensonges - ShadEOS arr√™t√©")
            raise Exception(error_msg)
    
    def _simuler_execution_lucie_chien(self, ordres: Dict[str, Any]) -> Dict[str, Any]:
        """üêï Simulation temporaire d'ex√©cution par Lucie/Chien"""
        return {
            'timestamp': datetime.now().isoformat(),
            'ordres_recus': ordres,
            'actions_executees': len(ordres['actions_demandees']),
            'success': True,
            'resultats': [
                'Logs analys√©s: 15 fichiers',
                'Espace disque: 85% libre',
                'Processus: 12 actifs',
                'M√©triques collect√©es'
            ]
        }
    
    def get_status(self) -> Dict[str, Any]:
        """üìä √âtat actuel de ShadEOS"""
        return {
            'running': self.running,
            'cycle_count': self.memory['cycle_count'],
            'autonomy_level': self.autonomy_level,
            'memory_size': {
                'gemini_interactions': len(self.memory['interactions_gemini']),
                'ordres_lucie': len(self.memory['ordres_lucie']),
                'rapports_chien': len(self.memory['rapports_chien'])
            },
            'last_cycle_success': self._evaluer_dernier_cycle()
        }

if __name__ == "__main__":
    # Test basique
    shadeos = ShadEOSMaster()
    print("üñ§ ShadEOS Master - Test de base")
    
    # Ex√©cuter quelques cycles de test
    for i in range(3):
        result = shadeos.executer_cycle_complet()
        print(f"Cycle {result['cycle']}: {'‚úÖ' if result['success'] else '‚ùå'}")
        time.sleep(1)
    
    # Afficher le statut final
    status = shadeos.get_status()
    print(f"üìä Statut final: {status}")
